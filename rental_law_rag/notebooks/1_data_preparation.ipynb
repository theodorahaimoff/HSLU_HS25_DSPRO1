{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe72a382-dd3f-4d16-9314-c262cd920df7",
   "metadata": {},
   "source": [
    "# Data Preparation (PDF ‚Üí JSON)\n",
    "\n",
    "**Goal:**  \n",
    "Convert all Swiss rental-law PDFs (OR, VMWG, StGB) into clean, structured JSON files ‚Äî  \n",
    "where **each JSON = exactly one legal article**.\n",
    "\n",
    "This makes later retrieval and referencing much easier and more accurate.\n",
    "\n",
    "**Context:**  \n",
    "- Splitting at *article-level granularity* instead of page chunks.\n",
    "- Adding metadata (law name, article number, source).\n",
    "- Keeping a clean and reproducible data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53649cda-cc1d-447a-a4d8-d8ffea090b62",
   "metadata": {},
   "source": [
    "‚öôÔ∏è Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82ddbfc4-2fc0-4899-96ca-ebb70ba0b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "DATA_RAW = Path(\"data/raw\")     # PDFs go here\n",
    "DATA_JSON = Path(\"data/json\")   # Will hold one JSON per article\n",
    "DATA_JSON.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f0df7-aa43-4c81-b064-46cef2d0c698",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "We‚Äôll use:\n",
    "- **PyMuPDF (fitz)** to extract text page by page.  \n",
    "- **Regex** to detect ‚ÄúArt. XXX‚Äù headers.  \n",
    "- **tqdm** for nice progress bars.  \n",
    "\n",
    "We‚Äôll store results as JSON so each file can be directly embedded later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf824fb-0f2e-4b2f-abf8-72055c1cef0b",
   "metadata": {},
   "source": [
    "üß© Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d01e22-221c-4397-88b5-69d5b2b41f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cleaning & Splitting ---\n",
    "ART_HEADER = re.compile(r\"(?m)^\\s*(Art\\.\\s*\\d+[a-zA-Z]*\\b[^\\n]*)\\s*$\")\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    \"\"\"Normalize whitespace and remove artifacts.\"\"\"\n",
    "    t = t.replace(\"\\x0c\", \" \").replace(\"\\u00ad\", \"\")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\\n\", \"\\n\", t)\n",
    "    t = re.sub(r\"\\n\\s+\", \"\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def read_pdf_text(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract all text from a PDF using PyMuPDF.\"\"\"\n",
    "    pages = []\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for p in doc:\n",
    "            pages.append(p.get_text(\"text\"))\n",
    "    return clean_text(\"\\n\".join(pages))\n",
    "\n",
    "def split_articles(full_text: str):\n",
    "    \"\"\"Split a document into (header, body) per article.\"\"\"\n",
    "    headers = list(ART_HEADER.finditer(full_text))\n",
    "    articles = []\n",
    "    for i, m in enumerate(headers):\n",
    "        start = m.start()\n",
    "        end = headers[i+1].start() if i+1 < len(headers) else len(full_text)\n",
    "        block = full_text[start:end].strip()\n",
    "        header_line = m.group(1).strip()\n",
    "        body = block[len(header_line):].strip()\n",
    "        articles.append((header_line, body))\n",
    "    return articles\n",
    "\n",
    "def parse_article_number(header_line: str):\n",
    "    m = re.search(r\"Art\\.\\s*(\\d+[a-zA-Z]*)\", header_line)\n",
    "    return m.group(1) if m else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692ff70-6b89-4c3b-8d32-786c3e3e4899",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "Each article in Swiss laws starts with `Art.` followed by a number or letter.  \n",
    "This regex isolates those headers and splits the PDF into article blocks.  \n",
    "We also extract the article number (e.g. `269d`, `325bis`) for metadata.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446a8b8-7628-4e3e-98c8-04f285bb73b1",
   "metadata": {},
   "source": [
    "üìÑ Process PDFs ‚Üí Save JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3792d33-cedf-43fa-a375-059cbf7cf35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_law_tag(stem: str) -> str:\n",
    "    s = stem.upper()\n",
    "    if \"OR\" in s: return \"OR\"\n",
    "    if \"VMWG\" in s: return \"VMWG\"\n",
    "    if \"STGB\" in s or \"STG\" in s: return \"StGB\"\n",
    "    return stem\n",
    "\n",
    "def ingest_pdf(pdf_path: Path):\n",
    "    law = detect_law_tag(pdf_path.stem)\n",
    "    text = read_pdf_text(pdf_path)\n",
    "    articles = split_articles(text)\n",
    "\n",
    "    out_dir = DATA_JSON / law\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for header, body in articles:\n",
    "        art_nr = parse_article_number(header) or \"NA\"\n",
    "        payload = {\n",
    "            \"law\": law,\n",
    "            \"article\": art_nr,\n",
    "            \"header\": header,\n",
    "            \"text\": body,\n",
    "            \"source\": pdf_path.name\n",
    "        }\n",
    "        out_fp = out_dir / f\"{law}_Art_{art_nr}.json\"\n",
    "        out_fp.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    return len(articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b60eaf-8182-491d-9671-57b694ff3b70",
   "metadata": {},
   "source": [
    "‚ñ∂Ô∏è Run Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa56162-5548-4ca9-b05a-494da8fb864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDFs: ['OR.pdf', 'STGB.pdf', 'VMWG.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! Created ~118 article JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdfs = sorted(DATA_RAW.glob(\"*.pdf\"))\n",
    "print(\"Found PDFs:\", [p.name for p in pdfs])\n",
    "\n",
    "total_articles = 0\n",
    "for pdf in tqdm(pdfs, desc=\"Processing PDFs\"):\n",
    "    total_articles += ingest_pdf(pdf)\n",
    "\n",
    "print(f\"‚úÖ Done! Created ~{total_articles} article JSON files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba2a87-5e2a-40d8-b798-c2f10275f14c",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "Each PDF is scanned and split into articles.\n",
    "Every JSON file now represents **exactly one article** (e.g. `OR_Art_269d.json`).\n",
    "We'll use these later to build embeddings with ChromaDB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b671023-4c5a-4d2f-ba05-9d6f86ed54aa",
   "metadata": {},
   "source": [
    "üëÄ Quick Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d263b6d-054e-4d45-802e-a4b745ae7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: OR_Art_256b.json\n",
      "Header: Art. 256b, Abgaben und Lasten\n",
      "Excerpt: Der Vermieter tr√§gt die mit der Sache verbundenen Lasten und √∂ffentlichen Abgaben....\n",
      "\n",
      "File: OR_Art_259.json\n",
      "Header: Art. 259, M√§ngel w√§hrend der Mietdauer, Pflicht des Mieters zu kleinen Reinigungen u.\n",
      "Excerpt: Ausbesserungen\n",
      "Der Mieter muss M√§ngel, die durch kleine, f√ºr den gew√∂hnlichen Unterhalt erforderliche Reinigungen\n",
      "oder Ausbesserungen behoben werden k√∂nnen, nach Ortsgebrauch auf eigene\n",
      "Kosten beseitigen....\n",
      "\n",
      "File: OR_Art_257d.json\n",
      "Header: Art. 257d, Zahlungsr√ºckstand des Mieters\n",
      "Excerpt: 1 Ist der Mieter nach der √úbernahme der Sache mit der Zahlung f√§lliger Mietzinse oder Nebenkosten\n",
      "im R√ºckstand, so kann ihm der Vermieter schriftlich eine Zahlungsfrist setzen und\n",
      "ihm androhen, dass bei unben√ºtztem Ablauf der Frist das Mietverh√§ltnis...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = list((DATA_JSON / \"OR\").glob(\"*.json\"))[:3]\n",
    "for s in samples:\n",
    "    print(\"File:\", s.name)\n",
    "    data = json.loads(s.read_text(encoding=\"utf-8\"))\n",
    "    print(f\"Header: {data['header']}\")\n",
    "    print(f\"Excerpt: {data['text'][:250]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73b748-7196-463d-9f2a-b0ffb78d98fb",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "We quickly check that:\n",
    "- Articles are correctly separated.  \n",
    "- Text doesn‚Äôt include the next article.  \n",
    "- Metadata (law, article number) is stored correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61054871-a2be-4637-b3d2-6d10c65374a1",
   "metadata": {},
   "source": [
    "# ‚úÖ Summary\n",
    "We now have a clean, article-level dataset ready for indexing.\n",
    "\n",
    "**Next notebook: `2_Indexing_and_Retrieval.ipynb`**\n",
    "We'll:\n",
    "- Load all JSONs,\n",
    "- Embed them with Sentence Transformers,\n",
    "- Store them in a persistent ChromaDB collection for fast semantic search.\n",
    "\n",
    "**Benefits of this structure**\n",
    "- Easier to debug and explain\n",
    "- Perfect granularity (one legal article per data point)\n",
    "- Can easily add new laws or update existing ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1896fa-750d-462f-888b-b84f05cb6d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
