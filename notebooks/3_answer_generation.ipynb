{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ed98cc-234a-4724-af0e-e0afcc4f9e35",
   "metadata": {},
   "source": [
    "# Answering & Evaluation (Chroma → OpenAI)\n",
    "\n",
    "Take retrieved legal articles (from Chroma) and generate a **grounded, structured answer** using the GPT-4o-mini model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e55bf20-f2f9-4ee1-a42f-c148f7896315",
   "metadata": {},
   "source": "## Imports & Paths"
  },
  {
   "cell_type": "code",
   "id": "cf63ef16-8ba3-491d-80c0-eba0cc9eb018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:28.532244Z",
     "start_time": "2025-11-07T19:32:28.528772Z"
    }
   },
   "source": [
    "import os, json, logging\n",
    "from pathlib import Path\n",
    "import streamlit as st\n",
    "from chromadb.config import Settings\n",
    "from openai import OpenAI\n",
    "from jsonschema import validate\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "# Retrieval knobs\n",
    "TOP_K  = 5\n",
    "PRE_K  = 20\n",
    "MAX_CTX_CHARS = 8000\n",
    "\n",
    "logger = logging.getLogger(\"SwissRentalLawApp\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Chroma Configuration",
   "id": "236999f247c0f318"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:28.598276Z",
     "start_time": "2025-11-07T19:32:28.593540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_base_dir() -> Path:\n",
    "    \"\"\"\n",
    "    Returns the project base directory that works both:\n",
    "    - in normal scripts (via __file__)\n",
    "    - in notebooks (via current working directory)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Path(__file__).resolve().parent\n",
    "    except NameError:\n",
    "        # __file__ not defined (e.g., in Jupyter or interactive)\n",
    "        return Path(os.getcwd()).resolve()\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def load_manifest():\n",
    "    try:\n",
    "        base_dir =  get_base_dir()\n",
    "        store_dir = (base_dir.parent / \"store\").resolve()\n",
    "        mf = json.loads((store_dir / \"manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "        mf[\"store_dir\"] = str(store_dir / mf[\"dir\"])         # absolute path to the versioned dir\n",
    "        return mf\n",
    "    except Exception as e:\n",
    "        st.sidebar.error(f\"Manifest error: {e}\")\n",
    "        return None\n",
    "\n",
    "def _mf():\n",
    "    return load_manifest()\n",
    "\n",
    "CHROMA_SETTINGS = Settings(anonymized_telemetry=False, allow_reset=True)\n",
    "\n",
    "def _embedding_model_name():\n",
    "    return _mf()[\"model\"]\n",
    "\n",
    "def _collection_name():\n",
    "    return _mf()[\"collection\"]\n",
    "\n",
    "def _chroma_dir():\n",
    "    return _mf()[\"store_dir\"]\n",
    "\n",
    "def _expected_dim():\n",
    "    return _mf()[\"dim\"]"
   ],
   "id": "f870c71614566e7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OpenAI Client",
   "id": "1f1a6a44c8e6867f"
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:28.648706Z",
     "start_time": "2025-11-07T19:32:28.645394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def _get_oai_token():\n",
    "    try:\n",
    "        s = dict(st.secrets)\n",
    "        return s.get(\"env\", {}).get(\"OAI_TOKEN\") or os.getenv(\"OAI_TOKEN\") or \"\"\n",
    "    except Exception:\n",
    "        return os.getenv(\"OAI_TOKEN\") or \"\"\n",
    "\n",
    "def get_oai_client():\n",
    "    key = _get_oai_token()\n",
    "    if not key:\n",
    "        raise EnvironmentError(\"OpenAI token missing (set OAI_TOKEN or OPENAI_API_KEY).\")\n",
    "    return OpenAI(api_key=key)\n",
    "\n",
    "def embed_query(text: str) -> list:\n",
    "    client = get_oai_client()\n",
    "    resp = client.embeddings.create(model=_embedding_model_name(), input=text)\n",
    "    return resp.data[0].embedding"
   ],
   "id": "feb612144bcb127f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "5c020c75-2b9f-4d5e-aa44-81a6f01eb2a6",
   "metadata": {},
   "source": "## Chroma Client"
  },
  {
   "cell_type": "code",
   "id": "1b9aa3b1-e8f6-43e8-9fca-8e76239a7035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:28.705134Z",
     "start_time": "2025-11-07T19:32:28.700331Z"
    }
   },
   "source": [
    "def get_client():\n",
    "    import chromadb\n",
    "    return chromadb.PersistentClient(path=_chroma_dir(), settings=CHROMA_SETTINGS)\n",
    "\n",
    "def get_collection(name: str | None = None):\n",
    "    name = name or _collection_name()\n",
    "    col = get_client().get_collection(name)\n",
    "    logger.info(f\"Loaded Chroma collection '{name}' with {col.count()} entries.\")\n",
    "    return col"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "tags": [
     "noexport"
    ],
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:28.755654Z",
     "start_time": "2025-11-07T19:32:28.751178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _assert_dim(col, expected=_expected_dim()):\n",
    "    peek = col.get(limit=1, include=[\"embeddings\"])\n",
    "    if peek.get(\"embeddings\"):\n",
    "        dim = len(peek[\"embeddings\"][0])\n",
    "        if dim != expected:\n",
    "            raise RuntimeError(f\"Index dim={dim} != manifest dim={expected}. Update manifest or rebuild index.\")"
   ],
   "id": "4ed29fe14a6c96b2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "5dd82796-4a63-448a-9f3c-27757e98fa26",
   "metadata": {},
   "source": "### Check collection & doc count"
  },
  {
   "cell_type": "code",
   "id": "b9d2e2df-5c06-4532-ba7c-15adfe11162c",
   "metadata": {
    "tags": [
     "noexport"
    ],
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:29.107287Z",
     "start_time": "2025-11-07T19:32:28.810099Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # local dev only\n",
    "    try:\n",
    "        col = get_collection()\n",
    "        print(\"Collection:\", col, \"| count:\", col.count())\n",
    "        _assert_dim(col)\n",
    "    except Exception as e:\n",
    "        print(\"Chroma check failed:\", e)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: Collection(id=61cd5ed0-2512-43b5-bcc3-2af45a2d082b, name=swiss_private_rental_law_oai_v2025-11-07) | count: 118\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "0e590a5e-55c8-4f2d-88d0-ba768db43f33",
   "metadata": {},
   "source": "### Retrieve & re-rank + pack context"
  },
  {
   "cell_type": "code",
   "id": "a9c7752a-281f-4d67-97dd-57f69d968990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:29.120552Z",
     "start_time": "2025-11-07T19:32:29.114868Z"
    }
   },
   "source": [
    "def retrieve(query: str, k: int = TOP_K, k_pre: int = PRE_K, collection_name: str | None = None):\n",
    "    col = get_collection(collection_name)\n",
    "    q_emb = embed_query(query)\n",
    "    res = col.query(query_embeddings=[q_emb], n_results=k_pre, include=['documents','metadatas','distances'])\n",
    "    docs  = res.get('documents', [[]])[0]\n",
    "    metas = res.get('metadatas', [[]])[0]\n",
    "    dists = res.get('distances', [[]])[0]\n",
    "    prelim = sorted(list(zip(docs, metas, dists)), key=lambda x: x[2])\n",
    "    return prelim[:k]\n",
    "\n",
    "def pack_context(retrieved, max_chars=MAX_CTX_CHARS, per_source_cap=3):\n",
    "    ctx, total, seen = [], 0, {}\n",
    "    for doc, meta, dist in retrieved:\n",
    "        key = (meta.get(\"law\"), meta.get(\"article\"))\n",
    "        seen[key] = seen.get(key, 0) + 1\n",
    "        if seen[key] > per_source_cap:\n",
    "            continue\n",
    "        stamp = f\"[{meta.get('law','?')} {meta.get('title','?')} – {meta.get('source')}]\"\n",
    "        block = f\"{stamp}\\n{doc.strip()}\\n\\n\"\n",
    "        if total + len(block) > max_chars:\n",
    "            break\n",
    "        ctx.append(block)\n",
    "        total += len(block)\n",
    "    return \"\".join(ctx)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "84b79216-cced-44d5-b436-e225cb69dc8b",
   "metadata": {},
   "source": [
    "## Prompt design\n",
    "\n",
    "We force a strict structure for answers and **forbid** using anything outside the provided context.\n",
    "\n",
    "**Format required:**\n",
    "1) One-sentence answer.\n",
    "2) Numbered steps/options (say if they apply to Tenant or Landlord).\n",
    "3) Forms required (exact names if present).\n",
    "4) Sources (e.g. OR Art.x, Name).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c3d7d76-b087-4316-898e-48952d977dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:29.175694Z",
     "start_time": "2025-11-07T19:32:29.166716Z"
    }
   },
   "source": [
    "# --- Prompt (escaped braces; single {question}) ---\n",
    "PROMPT = \"\"\"You are a Swiss rental-law assistant.\n",
    "Answer ONLY from the CONTEXT. If insufficient, say so.\n",
    "Write in German (Switzerland) in strictly 'Du'-Form.\n",
    "Do NOT refer to yourself, your role, or your identity in the answer.\n",
    "Start directly with the content requested (no introductions).\n",
    "Return STRICTLY a JSON object with this shape, no extra keys, no markdown fences, no numbering:\n",
    "\n",
    "\"answer\": \"one concise sentence\",\\\\n'\n",
    "\"steps\": [\"one unique action per entry for the given perspective, no numbering, 2-4 items\"],\\\\n'\n",
    "\"forms\": [\"exact official names from CONTEXT, or empty array\"],\\\\n'\n",
    "\"references\": [{{\"law\": \"OR\", \"title\": \"Art.x, Article Title\", \"source\": \"OR.pdf\"}}]\\\\n'\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# --- JSON schema for validation ---\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"answer\": {\"type\": \"string\"},\n",
    "        \"steps\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\", \"maxLength\": 180},\n",
    "            \"minItems\": 2,\n",
    "            \"maxItems\": 8,\n",
    "            \"uniqueItems\": False\n",
    "        },\n",
    "        \"forms\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"minItems\": 0,\n",
    "            \"maxItems\": 10\n",
    "        },\n",
    "        \"references\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"law\":   {\"type\": \"string\"},\n",
    "                    \"title\": {\"type\": \"string\"},\n",
    "                    \"source\":{\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"law\", \"title\", \"source\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"answer\", \"references\"]\n",
    "}\n",
    "\n",
    "\n",
    "def answer_with_openai(question: str, perspective: str, k=TOP_K, model=\"gpt-4o-mini\", max_chars=MAX_CTX_CHARS):\n",
    "    hits = retrieve(question, k=k)\n",
    "    context = pack_context(hits, max_chars=max_chars)\n",
    "\n",
    "    prompt = PROMPT.format(context=context, question=f\"Perspective: {perspective}, Question: {question}\")\n",
    "\n",
    "    client = get_oai_client()\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": prompt}]},\n",
    "            {\"role\": \"user\",   \"content\": [{\"type\": \"text\", \"text\":\n",
    "                \"Beantworte die Frage gemäss obigen Vorgaben. Fülle die Felder des JSON-Schemas aus. \"\n",
    "                \"Sprache: Deutsch (Schweiz), Du-Form. Für 'steps' gilt: Gib 2–8 kurze Einträge zurück, \"\n",
    "                \"jeder Eintrag genau EIN Schritt, EINE Zeile, KEINE Nummerierung oder Zeilenumbrüche. \"\n",
    "                \"Für 'forms': gib die genauen offiziellen Bezeichnungen aus dem CONTEXT zurück (leer, wenn keine). \"\n",
    "                \"Gib NUR JSON zurück.\"\n",
    "            }]}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    content = resp.choices[0].message.content or \"\"\n",
    "    parsed = json.loads(content)  # will raise clearly if not JSON\n",
    "    validate(instance=parsed, schema=schema)\n",
    "\n",
    "    steps = parsed.get(\"steps\") or []\n",
    "    forms = parsed.get(\"forms\") or []\n",
    "    refs  = parsed.get(\"references\") or []\n",
    "\n",
    "    # normalize\n",
    "    if isinstance(steps, str): steps = [s.strip() for s in steps.split(\"\\n\") if s.strip()]\n",
    "    if isinstance(forms, str): forms = [f.strip() for f in forms.split(\"\\n\") if f.strip()]\n",
    "\n",
    "    return (parsed.get(\"answer\",\"\").strip(), steps, forms, refs, hits)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Local Testing",
   "id": "a2d09e1c-5393-434c-9ff5-6d9049bf379f"
  },
  {
   "cell_type": "markdown",
   "id": "c031b75e-e2b1-4fba-8537-752bdc8db347",
   "metadata": {},
   "source": "### Single question test"
  },
  {
   "cell_type": "code",
   "id": "e0ea2ea4-23d0-469b-a6ee-19ba10736c78",
   "metadata": {
    "tags": [
     "noexport"
    ],
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:29.382780Z",
     "start_time": "2025-11-07T19:32:29.222523Z"
    }
   },
   "source": [
    "def single_question_test():\n",
    "    q = \"Wie fechte ich eine Mietzinserhöhung an? Welches Formular ist nötig?\"\n",
    "    ans, steps, forms, references, hits = answer_with_openai(q, perspective=\"Mieter:in\", k=6)\n",
    "    print(\"=== ANSWER ===\\n\", ans, \"\\n\")\n",
    "    print(\"=== STEPS ===\\n\", steps, \"\\n\")\n",
    "    print(\"=== FORMS ===\\n\", forms, \"\\n\")\n",
    "    print(\"=== SOURCES ===\\n\", references, \"\\n\")\n",
    "\n",
    "single_question_test()"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "OpenAI token missing (set OAI_TOKEN or OPENAI_API_KEY).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== FORMS ===\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, forms, \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      7\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== SOURCES ===\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, references, \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43msingle_question_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36msingle_question_test\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34msingle_question_test\u001B[39m():\n\u001B[32m      2\u001B[39m     q = \u001B[33m\"\u001B[39m\u001B[33mWie fechte ich eine Mietzinserhöhung an? Welches Formular ist nötig?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     ans, steps, forms, references, hits = \u001B[43manswer_with_openai\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mperspective\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mMieter:in\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== ANSWER ===\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, ans, \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      5\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== STEPS ===\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, steps, \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 57\u001B[39m, in \u001B[36manswer_with_openai\u001B[39m\u001B[34m(question, perspective, k, model, max_chars)\u001B[39m\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34manswer_with_openai\u001B[39m(question: \u001B[38;5;28mstr\u001B[39m, perspective: \u001B[38;5;28mstr\u001B[39m, k=TOP_K, model=\u001B[33m\"\u001B[39m\u001B[33mgpt-4o-mini\u001B[39m\u001B[33m\"\u001B[39m, max_chars=MAX_CTX_CHARS):\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m     hits = \u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     58\u001B[39m     context = pack_context(hits, max_chars=max_chars)\n\u001B[32m     60\u001B[39m     prompt = PROMPT.format(context=context, question=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPerspective: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mperspective\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Question: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquestion\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mretrieve\u001B[39m\u001B[34m(query, k, k_pre, collection_name)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mretrieve\u001B[39m(query: \u001B[38;5;28mstr\u001B[39m, k: \u001B[38;5;28mint\u001B[39m = TOP_K, k_pre: \u001B[38;5;28mint\u001B[39m = PRE_K, collection_name: \u001B[38;5;28mstr\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m      2\u001B[39m     col = get_collection(collection_name)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     q_emb = \u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     res = col.query(query_embeddings=[q_emb], n_results=k_pre, include=[\u001B[33m'\u001B[39m\u001B[33mdocuments\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mmetadatas\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mdistances\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m      5\u001B[39m     docs  = res.get(\u001B[33m'\u001B[39m\u001B[33mdocuments\u001B[39m\u001B[33m'\u001B[39m, [[]])[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36membed_query\u001B[39m\u001B[34m(text)\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34membed_query\u001B[39m(text: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28mlist\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     client = \u001B[43mget_oai_client\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m     resp = client.embeddings.create(model=_embedding_model_name(), \u001B[38;5;28minput\u001B[39m=text)\n\u001B[32m     17\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m resp.data[\u001B[32m0\u001B[39m].embedding\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mget_oai_client\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      9\u001B[39m key = _get_oai_token()\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m key:\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mOpenAI token missing (set OAI_TOKEN or OPENAI_API_KEY).\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m OpenAI(api_key=key)\n",
      "\u001B[31mOSError\u001B[39m: OpenAI token missing (set OAI_TOKEN or OPENAI_API_KEY)."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "5b65fa32-a64c-4958-bf4f-a63d14ca5124",
   "metadata": {},
   "source": "### Batch evaluation"
  },
  {
   "cell_type": "code",
   "id": "e30b5afa-e1d9-47ec-b9b9-c06267bb8b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:29.396210846Z",
     "start_time": "2025-11-07T16:50:50.151079Z"
    },
    "tags": [
     "noexport"
    ]
   },
   "source": [
    "def batch_evaluation():\n",
    "    eval_questions = [\n",
    "        (\"Wie fechte ich eine Mietzinserhöhung an? Welches Formular ist nötig?\", \"Mieter:in\"),\n",
    "        (\"Welche Rechte habe ich bei Mängeln in der Wohnung?\", \"Mieter:in\"),\n",
    "        (\"Darf der Vermieter während laufendem Schlichtungsverfahren kündigen?\", \"Vermieter:in\"),\n",
    "        (\"Wann sind Mietzinserhöhungen wegen energetischer Verbesserungen zulässig?\", \"Vermieter:in\"),\n",
    "    ]\n",
    "\n",
    "    for q, perspective in eval_questions:\n",
    "        print(\"\\n\" + \"=\"*150)\n",
    "        print(\"Q:\", q, \"| Perspective:\", perspective)\n",
    "        print(\"=\"*150)\n",
    "        ans, steps, forms, references, hits = answer_with_openai(q, perspective=perspective, k=6)\n",
    "        print(\"\\n--- ANSWER ---\\n\", ans[:2000])  # trim for display\n",
    "        print(\"=== STEPS ===\\n\", steps[:2000])\n",
    "        print(\"=== FORMS ===\\n\", forms)\n",
    "        print(\"=== SOURCES ===\\n\", references)\n",
    "\n",
    "batch_evaluation()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:32:29.396599164Z",
     "start_time": "2025-11-07T16:50:50.243842Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b51a0f7b-163b-49c9-8779-f6525307f794",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
