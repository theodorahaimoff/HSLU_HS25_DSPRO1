{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ed98cc-234a-4724-af0e-e0afcc4f9e35",
   "metadata": {},
   "source": [
    "# Answering & Evaluation (Chroma → Ollama)\n",
    "\n",
    "**Goal:** Take retrieved legal articles (from Chroma) and generate a **grounded, structured answer** using a *local* Ollama model (e.g., `llama3:8b`).\n",
    "\n",
    "**What we’ll do:**\n",
    "1) Load the Chroma collection\n",
    "2) Retrieve top-K relevant articles (uses the helpers from Notebook 2)\n",
    "3) Build a clean context block with citations like `[OR Art. 269d – OR.pdf]`\n",
    "4) Call **Ollama HTTP API** locally to generate the answer\n",
    "5) Run a small evaluation set of typical user questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e55bf20-f2f9-4ee1-a42f-c148f7896315",
   "metadata": {},
   "source": [
    "Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "id": "cf63ef16-8ba3-491d-80c0-eba0cc9eb018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:23.741403Z",
     "start_time": "2025-11-07T14:43:21.275437Z"
    }
   },
   "source": [
    "import os, json, logging\n",
    "from pathlib import Path\n",
    "\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "try:\n",
    "    import streamlit as st  # noqa\n",
    "except Exception:\n",
    "    st = None\n",
    "\n",
    "def _get_oai_token():\n",
    "    try:\n",
    "        s = dict(st.secrets)\n",
    "        return s.get(\"env\", {}).get(\"OAI_TOKEN\") or os.getenv(\"OAI_TOKEN\") or \"\"\n",
    "    except Exception:\n",
    "        return os.getenv(\"OAI_TOKEN\") or \"\"\n",
    "\n",
    "OAI_TOKEN = _get_oai_token()\n",
    "\n",
    "if not OAI_TOKEN:\n",
    "    if st is not None:\n",
    "        # stop Streamlit cleanly with a visible error\n",
    "        st.error(\"OpenAI Token fehlt. Lege es in `.streamlit/secrets.toml` unter `[env].OAI_TOKEN` \"\n",
    "                 \"oder als Env-Var `OAI_TOKEN` an.\")\n",
    "        st.stop()\n",
    "    else:\n",
    "        # non-Streamlit context (CLI/tests)\n",
    "        raise EnvironmentError(\"OAI_TOKEN missing. Set env var or Streamlit secret.\")\n",
    "\n",
    "OAI_CLIENT = OpenAI(api_key=OAI_TOKEN)\n",
    "OAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # Jupyter fallback\n",
    "    BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "CHROMA_DIR = (BASE_DIR.parent / \"store\").resolve()\n",
    "CHROMA_COLLECTION = \"swiss_private_rental_law_oai\"\n",
    "\n",
    "EMBED_MODEL_NAME = \"text-embedding-3-small\"\n",
    "\n",
    "# Retrieval knobs\n",
    "TOP_K  = 5\n",
    "PRE_K  = 20\n",
    "MAX_CTX_CHARS = 8000\n",
    "\n",
    "\n",
    "logging.getLogger(\"chromadb\").setLevel(logging.DEBUG)\n",
    "# Disable analytics/telemetry\n",
    "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\"\n",
    "os.environ[\"POSTHOG_DISABLED\"] = \"true\"\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[0;93m2025-11-07 15:43:21.576667651 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card5/device/vendor\"\u001B[m\n",
      "2025-11-07 15:43:23.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-07 15:43:23.584 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/theodora/.local/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-11-07 15:43:23.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-07 15:43:23.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-07 15:43:23.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "66481d3f-7563-4d1b-9baf-3c8e9ee77e7f",
   "metadata": {},
   "source": [
    "We verify:\n",
    "- Chroma store exists and is readable\n",
    "- The collection is present\n",
    "- Ollama is reachable and model is available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c020c75-2b9f-4d5e-aa44-81a6f01eb2a6",
   "metadata": {},
   "source": [
    "Chroma & Embedder helpers (same logic as indexing_and_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b9aa3b1-e8f6-43e8-9fca-8e76239a7035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:23.749677Z",
     "start_time": "2025-11-07T14:43:23.746840Z"
    }
   },
   "source": [
    "def get_client():\n",
    "    return chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
    "\n",
    "def get_collection(name=CHROMA_COLLECTION):\n",
    "    client = get_client()\n",
    "    return client.get_collection(name)\n",
    "\n",
    "def embed_query(text: str) -> list[float]:\n",
    "    resp = OAI_CLIENT.embeddings.create(\n",
    "        model=EMBED_MODEL_NAME,\n",
    "        input=text\n",
    "    )\n",
    "    return resp.data[0].embedding\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "5dd82796-4a63-448a-9f3c-27757e98fa26",
   "metadata": {},
   "source": [
    "Check collection & doc count"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9d2e2df-5c06-4532-ba7c-15adfe11162c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:23.991904Z",
     "start_time": "2025-11-07T14:43:23.794113Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # local dev only\n",
    "    try:\n",
    "        col = get_collection()\n",
    "        print(\"Collection:\", CHROMA_COLLECTION, \"| count:\", col.count())\n",
    "    except Exception as e:\n",
    "        print(\"Chroma check failed:\", e)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: swiss_private_rental_law_oai | count: 118\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "73e0d9fc-9f7b-4721-abd4-5f54fff8cad0",
   "metadata": {},
   "source": [
    "We reuse a lightweight retrieval pipeline:\n",
    "- Embed the query\n",
    "- Query Chroma (optionally prefetch `PRE_K` and re-rank)\n",
    "- Format a **compact context** with clear citations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e590a5e-55c8-4f2d-88d0-ba768db43f33",
   "metadata": {},
   "source": [
    "Retrieve & (optional) re-rank + pack context"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9c7752a-281f-4d67-97dd-57f69d968990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.021483Z",
     "start_time": "2025-11-07T14:43:24.016302Z"
    }
   },
   "source": [
    "def retrieve(query: str, k: int = TOP_K, k_pre: int = PRE_K, collection_name: str = CHROMA_COLLECTION):\n",
    "    col = get_collection(collection_name)\n",
    "\n",
    "    # 1) embed the query with OpenAI\n",
    "    q_emb = embed_query(query)\n",
    "\n",
    "    # 2) query Chroma (no reranker, distance sort)\n",
    "    res = col.query(\n",
    "        query_embeddings=[q_emb],\n",
    "        n_results=k_pre,\n",
    "        include=['documents', 'metadatas', 'distances']\n",
    "    )\n",
    "\n",
    "    docs  = res.get('documents', [[]])[0]\n",
    "    metas = res.get('metadatas', [[]])[0]\n",
    "    dists = res.get('distances', [[]])[0]\n",
    "\n",
    "    prelim = list(zip(docs, metas, dists))\n",
    "    prelim = sorted(prelim, key=lambda x: x[2])  # smaller distance = closer\n",
    "    return prelim[:k]\n",
    "\n",
    "def pack_context(retrieved, max_chars=MAX_CTX_CHARS, per_source_cap=3):\n",
    "    #Build context string from retrieved docs.\n",
    "    ctx, total, seen = [], 0, {}\n",
    "\n",
    "    for doc, meta, dist in retrieved:\n",
    "        key = (meta.get(\"law\"), meta.get(\"article\"))\n",
    "        seen[key] = seen.get(key, 0) + 1\n",
    "        if seen[key] > per_source_cap:\n",
    "            continue\n",
    "\n",
    "        stamp = f\"[{meta.get('law','?')} {meta.get('title','?')} – {meta.get('source')}]\"\n",
    "        block = f\"{stamp}\\n{doc.strip()}\\n\\n\"\n",
    "        if total + len(block) > max_chars:\n",
    "            break\n",
    "\n",
    "        ctx.append(block)\n",
    "        total += len(block)\n",
    "    return \"\".join(ctx)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "84b79216-cced-44d5-b436-e225cb69dc8b",
   "metadata": {},
   "source": [
    "### Prompt design\n",
    "\n",
    "We force a strict structure for answers and **forbid** using anything outside the provided context.\n",
    "\n",
    "**Format required:**\n",
    "1) One-sentence answer.\n",
    "2) Numbered steps/options (say if they apply to Tenant or Landlord).\n",
    "3) Forms required (exact names if present).\n",
    "4) Articles to read next (e.g., Art. 269 OR; Art. 19 VMWG).\n",
    "\n",
    "Then **References** as `[LAW Art.X – filename]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c3d7d76-b087-4316-898e-48952d977dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.111229Z",
     "start_time": "2025-11-07T14:43:24.085696Z"
    }
   },
   "source": [
    "# --- Prompt (escaped braces; single {question}) ---\n",
    "PROMPT = \"\"\"You are a Swiss rental-law assistant.\n",
    "Answer ONLY from the CONTEXT. If insufficient, say so.\n",
    "Write in German (Switzerland) in strictly 'Du'-Form.\n",
    "Do NOT refer to yourself, your role, or your identity in the answer.\n",
    "Start directly with the content requested (no introductions).\n",
    "Return STRICTLY a JSON object with this shape, no extra keys, no markdown fences, no numbering:\n",
    "\n",
    "\"answer\": \"one concise sentence\",\\\\n'\n",
    "\"steps\": [\"one unique action per entry for the given perspective, no numbering, 2-6 items\"],\\\\n'\n",
    "\"forms\": [\"exact official names from CONTEXT, or empty array\"],\\\\n'\n",
    "\"references\": [{{\"law\": \"OR\", \"title\": \"Art.x, Article Title\", \"source\": \"OR.pdf\"}}]\\\\n'\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# --- JSON schema for validation ---\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"answer\": {\"type\": \"string\"},\n",
    "        \"steps\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\", \"maxLength\": 180},\n",
    "            \"minItems\": 2,\n",
    "            \"maxItems\": 8,\n",
    "            \"uniqueItems\": False\n",
    "        },\n",
    "        \"forms\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"minItems\": 0,\n",
    "            \"maxItems\": 10\n",
    "        },\n",
    "        \"references\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"law\":   {\"type\": \"string\"},\n",
    "                    \"title\": {\"type\": \"string\"},\n",
    "                    \"source\":{\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"law\", \"title\", \"source\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"answer\", \"references\"]\n",
    "}\n",
    "\n",
    "def answer_with_openai(question: str, perspective: str, k=TOP_K, model=OAI_MODEL, max_chars=MAX_CTX_CHARS):\n",
    "    \"\"\"\n",
    "    Query OpenAI with retrieved context and return:\n",
    "    (generated_answer, steps, forms, references, hits)\n",
    "    \"\"\"\n",
    "    # 1) Retrieve documents\n",
    "    hits = retrieve(question, k=k)\n",
    "    context = pack_context(hits, max_chars=max_chars)\n",
    "\n",
    "    # 2) Build prompt\n",
    "    prompt = PROMPT.format(\n",
    "        context=context,\n",
    "        question=f\"Perspective: {perspective}, Question: {question}\"\n",
    "    )\n",
    "\n",
    "    # 3) Call Chat Completions in JSON mode (SDK 2.7.1)\n",
    "    try:\n",
    "        resp = OAI_CLIENT.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": prompt}]},\n",
    "                {\"role\": \"user\",   \"content\": [{\"type\": \"text\", \"text\":\n",
    "                    \"Beantworte die Frage gemäss obigen Vorgaben. \"\n",
    "                    \"Fülle die Felder des JSON-Schemas aus. \"\n",
    "                    \"Sprache: Deutsch (Schweiz), Du-Form. \"\n",
    "                    \"Für 'steps' gilt: Gib 2–8 kurze Einträge zurück, \"\n",
    "                    \"jeder Eintrag genau EIN Schritt, EINE Zeile, KEINE Nummerierung oder Zeilenumbrüche. \"\n",
    "                    \"Für 'forms': gib die genauen offiziellen Bezeichnungen aus dem CONTEXT zurück (leer, wenn keine). \"\n",
    "                    \"Gib NUR JSON zurück.\"\n",
    "                }]}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"[OpenAI error]: {e}\", [], [], [], hits\n",
    "\n",
    "    # 4) Parse JSON\n",
    "    content = resp.choices[0].message.content or \"\"\n",
    "    try:\n",
    "        parsed = json.loads(content)\n",
    "    except Exception as e:\n",
    "        return f\"[Parse error]: {e}\\nRaw: {content}\", [], [], [], hits\n",
    "\n",
    "    # 5) Validate schema\n",
    "    try:\n",
    "        validate(instance=parsed, schema=schema)\n",
    "    except ValidationError as ve:\n",
    "        return f\"[Schema validation error]: {ve.message}\\nRaw: {parsed}\", [], [], [], hits\n",
    "\n",
    "    # 6) Normalize & return\n",
    "    answer_text = (parsed.get(\"answer\") or \"\").strip()\n",
    "\n",
    "    steps = parsed.get(\"steps\") or []\n",
    "    if isinstance(steps, str):\n",
    "        steps = [s.strip() for s in steps.split(\"\\n\") if s.strip()]\n",
    "\n",
    "    forms = parsed.get(\"forms\") or []\n",
    "    if isinstance(forms, str):\n",
    "        forms = [f.strip() for f in forms.split(\"\\n\") if f.strip()]\n",
    "\n",
    "    references = parsed.get(\"references\") or []\n",
    "\n",
    "    return answer_text, steps, forms, references, hits\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a2d09e1c-5393-434c-9ff5-6d9049bf379f",
   "metadata": {},
   "source": [
    "Try a realistic query and inspect the sources retrieved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031b75e-e2b1-4fba-8537-752bdc8db347",
   "metadata": {},
   "source": [
    "Single question test"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0ea2ea4-23d0-469b-a6ee-19ba10736c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.207871Z",
     "start_time": "2025-11-07T14:43:24.203809Z"
    }
   },
   "source": [
    "def single_question_test():\n",
    "    q = \"Wie fechte ich eine Mietzinserhöhung an? Welches Formular ist nötig?\"\n",
    "    ans, steps, forms, references, hits = answer_with_openai(q, perspective=\"Mieter:in\", k=6)\n",
    "    print(\"=== ANSWER ===\\n\", ans, \"\\n\")\n",
    "    print(\"=== STEPS ===\\n\", steps, \"\\n\")\n",
    "    print(\"=== FORMS ===\\n\", forms, \"\\n\")\n",
    "    print(\"=== SOURCES ===\\n\", references, \"\\n\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.234512Z",
     "start_time": "2025-11-07T14:43:24.232289Z"
    }
   },
   "cell_type": "code",
   "source": "#single_question_test()",
   "id": "3a2241ddb82aacd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "66991c55-6875-4543-bd7a-07bdb42a6d4e",
   "metadata": {},
   "source": [
    "We’ll run several canonical questions to check:\n",
    "- Structure & clarity of answers\n",
    "- That references point to the right law/articles\n",
    "- That forms are extracted when present (from VMWG, OR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65fa32-a64c-4958-bf4f-a63d14ca5124",
   "metadata": {},
   "source": [
    "Batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "e30b5afa-e1d9-47ec-b9b9-c06267bb8b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.285345Z",
     "start_time": "2025-11-07T14:43:24.279936Z"
    }
   },
   "source": [
    "def batch_evaluation():\n",
    "    eval_questions = [\n",
    "        (\"Wie fechte ich eine Mietzinserhöhung an? Welches Formular ist nötig?\", \"Mieter:in\"),\n",
    "        (\"Welche Rechte habe ich bei Mängeln in der Wohnung?\", \"Mieter:in\"),\n",
    "        (\"Darf der Vermieter während laufendem Schlichtungsverfahren kündigen?\", \"Vermieter:in\"),\n",
    "        (\"Wann sind Mietzinserhöhungen wegen energetischer Verbesserungen zulässig?\", \"Vermieter:in\"),\n",
    "    ]\n",
    "\n",
    "    for q, perspective in eval_questions:\n",
    "        print(\"\\n\" + \"=\"*150)\n",
    "        print(\"Q:\", q, \"| Perspective:\", perspective)\n",
    "        print(\"=\"*150)\n",
    "        ans, steps, forms, references, hits = answer_with_openai(q, perspective=perspective, k=6)\n",
    "        print(\"\\n--- ANSWER ---\\n\", ans[:2000])  # trim for display\n",
    "        print(\"=== STEPS ===\\n\", steps[:2000])\n",
    "        print(\"=== FORMS ===\\n\", forms)\n",
    "        print(\"=== SOURCES ===\\n\", references)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.341221Z",
     "start_time": "2025-11-07T14:43:24.335899Z"
    }
   },
   "cell_type": "code",
   "source": "#batch_evaluation()",
   "id": "f684cd2fa9688e4b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "a723f95c-132a-4aae-8f7a-902b37b740e4",
   "metadata": {},
   "source": [
    "### Common issues & fixes\n",
    "\n",
    "- **`Collection … count: 0`**  \n",
    "  Run Notebook 2 (Indexing) first to build the Chroma collection.\n",
    "\n",
    "- **Ollama error / not reachable**  \n",
    "  Ensure Ollama is running and the model is available:  \n",
    "  `ollama serve` (if needed), then `ollama pull llama3:8b`.\n",
    "\n",
    "- **Answers not following format**  \n",
    "  Tighten the prompt (you can add: “If you deviate from the format, respond: ‘Insufficient’”).\n",
    "\n",
    "- **Irrelevant citations**  \n",
    "  Increase `k` or enable cross-encoder re-rank (install `transformers`, `torch`).\n",
    "\n",
    "- **Prefer a specific law**  \n",
    "  Add a `where={\"law\": \"OR\"}` filter in the `col.query(...)` call inside `retrieve()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbdc1b-e1c3-4628-a6c6-a211aad32676",
   "metadata": {},
   "source": [
    "# ✅ Wrap-up\n",
    "\n",
    "- Answers are now generated **locally** with Ollama using strictly the retrieved legal context.\n",
    "- Citations are explicit and article-level, boosting trust.\n",
    "- You can toggle perspective (“Tenant” / “Landlord”) to tailor steps.\n",
    "\n",
    "**Next (optional):** Build a tiny Streamlit UI (`app.py`) with a dropdown (Perspective), textbox (Question), and output panel (Answer + References).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b51a0f7b-163b-49c9-8779-f6525307f794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T14:43:24.385365Z",
     "start_time": "2025-11-07T14:43:24.383742Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
