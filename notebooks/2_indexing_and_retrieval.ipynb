{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3c1d12-7aa9-4dfd-a889-a54fc6fc9635",
   "metadata": {},
   "source": [
    "# Indexing & Retrieval (JSON ‚Üí ChromaDB)\n",
    "\n",
    "**Goal:**  \n",
    "Turn our per-article JSON files into a *persistent* ChromaDB index with semantic search.\n",
    "\n",
    "**What we do here:**\n",
    "1) Load all article-level JSONs (from `data/json/LAW/LAW_Art_*.json`)  \n",
    "2) Embed each article using `sentence-transformers`  \n",
    "3) Store vectors + rich metadata in **ChromaDB (PersistentClient)**  \n",
    "4) Test retrieval (KNN) and inspect the hits for correctness\n",
    "\n",
    "**Why this matters:**  \n",
    "A clean, persistent index lets us (a) query instantly, (b) cite exact articles, and (c) add new sources later without redoing everything.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dd1be-6bc8-440c-86e9-5bd0ee4861ac",
   "metadata": {},
   "source": [
    "‚öôÔ∏è Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "id": "c9b30f09-aaae-4c12-b3ba-b8b82d7b2c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:03.996345Z",
     "start_time": "2025-11-07T15:00:03.991995Z"
    }
   },
   "source": [
    "import os, time, json, hashlib\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import chromadb, logging\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths (keep consistent with Notebook 1)\n",
    "DATA_JSON = Path(\"../data/json\")\n",
    "CHROMA_DIR = Path(\"../store\")\n",
    "CHROMA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collection name\n",
    "CHROMA_COLLECTION = \"swiss_private_rental_law_oai\"\n",
    "\n",
    "# Retrieval knobs\n",
    "TOP_K  = 5     # final results returned\n",
    "PRE_K  = 20    # prefetch for (optional) re-ranking\n",
    "\n",
    "EXPECTED_DIM = 1536\n",
    "\n",
    "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)\n",
    "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\"\n",
    "os.environ[\"POSTHOG_DISABLED\"] = \"true\"\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:04.107104Z",
     "start_time": "2025-11-07T15:00:04.063920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    import tomllib  # Python ‚â•3.11\n",
    "except ModuleNotFoundError:\n",
    "    import tomli as tomllib\n",
    "\n",
    "def load_oai_token() -> str:\n",
    "    \"\"\"\n",
    "    Loads the OpenAI API token from:\n",
    "    1) streamlit.secrets (if available)\n",
    "    2) .streamlit/secrets.toml (searched from cwd upwards)\n",
    "    3) Environment variables (OAI_TOKEN / OPENAI_API_KEY)\n",
    "    Works in both notebooks and Streamlit apps.\n",
    "    \"\"\"\n",
    "    # --- 1) Try Streamlit secrets ---\n",
    "    try:\n",
    "        import streamlit as st\n",
    "        token = dict(st.secrets).get(\"env\", {}).get(\"OAI_TOKEN\")\n",
    "        if token:\n",
    "            return token\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- 2) Try loading secrets.toml manually ---\n",
    "    # In Jupyter, we don‚Äôt have __file__, so we start from cwd.\n",
    "    cwd = Path.cwd()\n",
    "    candidates = [\n",
    "        cwd / \".streamlit\" / \"secrets.toml\",\n",
    "        cwd.parent / \".streamlit\" / \"secrets.toml\",\n",
    "        cwd.parent.parent / \".streamlit\" / \"secrets.toml\",\n",
    "    ]\n",
    "\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                with p.open(\"rb\") as f:\n",
    "                    data = tomllib.load(f)\n",
    "                token = data.get(\"env\", {}).get(\"OAI_TOKEN\")\n",
    "                if token:\n",
    "                    return token\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # --- 3) Fallback to environment vars ---\n",
    "    token = os.getenv(\"OAI_TOKEN\") or os.getenv(\"OPENAI_API_KEY\") or \"\"\n",
    "    return token\n",
    "\n",
    "def mask(t: str) -> str:\n",
    "    return t[:4] + \"‚Ä¶\" + t[-4:] if t and len(t) > 12 else \"(unset)\"\n",
    "\n",
    "OAI_TOKEN = load_oai_token()\n",
    "if not OAI_TOKEN:\n",
    "    raise EnvironmentError(\n",
    "        \"OpenAI key not found. Put it in `.streamlit/secrets.toml` under [env].OAI_TOKEN \"\n",
    "        \"or set OAI_TOKEN/OPENAI_API_KEY in your environment.\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ OpenAI token loaded:\", mask(OAI_TOKEN))\n",
    "\n",
    "OAI = OpenAI(api_key=OAI_TOKEN)\n",
    "EMBED_MODEL_NAME = \"text-embedding-3-small\""
   ],
   "id": "f2287c2216145491",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI token loaded: sk-s‚Ä¶QVsA\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "4cc38d09-8903-4c4c-be92-c2d7d84bb333",
   "metadata": {},
   "source": [
    "## Design Choices\n",
    "\n",
    "- **Per-article documents**: Each vector represents exactly one legal article (header + body).  \n",
    "- **Metadata**: We store `law`, `article`, `source`, `path`. This enables citations like **[OR Art. 269d ‚Äì OR.pdf]**.  \n",
    "- **Persistent index**: We use `chromadb.PersistentClient` so the index survives kernel restarts.  \n",
    "- **Normalised embeddings**: Improves cosine-similarity behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbab39-a03c-4843-9125-5f7722a403d3",
   "metadata": {},
   "source": [
    "üß± Chroma helpers"
   ]
  },
  {
   "cell_type": "code",
   "id": "9225f0da-a82e-486a-ad19-b6dda2b62e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:04.140082Z",
     "start_time": "2025-11-07T15:00:04.136362Z"
    }
   },
   "source": [
    "def get_client():\n",
    "    return chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
    "\n",
    "def get_collection(client=None, name=CHROMA_COLLECTION):\n",
    "    client = client or get_client()\n",
    "    return client.get_or_create_collection(name)\n",
    "\n",
    "def list_collections():\n",
    "    client = get_client()\n",
    "    return client.list_collections()\n",
    "\n",
    "def wipe_collection(name=CHROMA_COLLECTION):\n",
    "    client = get_client()\n",
    "    try:\n",
    "        client.delete_collection(name)\n",
    "        print(f\"Deleted collection: {name}\")\n",
    "    except Exception as e:\n",
    "        print(\"Delete failed:\", e)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "bc8d4e59-4b5c-49df-8f03-92412b028864",
   "metadata": {},
   "source": [
    "üß† Embedder init"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c7d6153-d918-4890-b8a2-d1a22211c7ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:04.206946Z",
     "start_time": "2025-11-07T15:00:04.202571Z"
    }
   },
   "source": [
    "def embed_batch(texts: List[str], *, model: str = EMBED_MODEL_NAME, retries: int = 5) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Embed a batch of texts with OpenAI, with basic retries on 429/5xx.\n",
    "    Hard-fail on 401 (bad/missing key).\n",
    "    \"\"\"\n",
    "    delay = 1.0\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            resp = OAI.embeddings.create(model=model, input=texts)\n",
    "            return [d.embedding for d in resp.data]\n",
    "        except Exception as e:\n",
    "            # Inspect common API errors\n",
    "            msg = str(e)\n",
    "            if \"401\" in msg or \"AuthenticationError\" in msg:\n",
    "                raise  # bad/missing key ‚Äì don't retry\n",
    "            if any(code in msg for code in (\"429\", \"500\", \"502\", \"503\", \"504\")) and attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "                delay = min(delay * 2, 10)\n",
    "                continue\n",
    "            # Not retriable or out of retries\n",
    "            raise\n",
    "\n",
    "def embed_query(text: str) -> List[float]:\n",
    "    return embed_batch([text])[0]\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "7f7a0088-8cbd-4a59-af36-3e61f2de03ca",
   "metadata": {},
   "source": [
    "üì• Load JSON files"
   ]
  },
  {
   "cell_type": "code",
   "id": "85f69684-e9eb-4494-b7bd-fb742b23d1b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:04.275976Z",
     "start_time": "2025-11-07T15:00:04.261851Z"
    }
   },
   "source": [
    "def load_article_jsons(root: Path = DATA_JSON):\n",
    "    files = sorted(root.rglob(\"*.json\"))  # recursively loads all JSONs under all subfolders\n",
    "    items = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            data = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "            doc_text = f\"{data.get('header','')}\\n{data.get('text','')}\".strip()\n",
    "            if len(doc_text) < 50:\n",
    "                continue\n",
    "            items.append({\n",
    "                \"id\": hashlib.md5(fp.as_posix().encode(\"utf-8\")).hexdigest()[:16],\n",
    "                \"text\": doc_text,\n",
    "                \"meta\": {\n",
    "                    \"source\": data.get(\"source\"),\n",
    "                    \"law\": data.get(\"law\"),\n",
    "                    \"title\": data.get(\"header\"),\n",
    "                    \"article\": data.get(\"article\"),\n",
    "                    \"path\": fp.as_posix()\n",
    "                }\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(\"Skip\", fp, \"‚Üí\", e)\n",
    "    return items\n",
    "\n",
    "articles = load_article_jsons()\n",
    "print(\"Found\", len(articles), \"articles.\")\n",
    "if articles:\n",
    "    print(\"Example:\", articles[0][\"meta\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 articles.\n",
      "Example: {'source': 'OR.pdf', 'law': 'OR', 'title': 'Art. 253, Begriff und Geltungsbereich, Begriff', 'article': '253', 'path': '../data/json/OR/OR_Art_253.json'}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "8af13946-1722-4738-bda5-e360734f5a24",
   "metadata": {},
   "source": [
    "## Build / Update the Index\n",
    "\n",
    "We‚Äôll:\n",
    "- batch-embed the articles,\n",
    "- add them to a persistent collection,\n",
    "- print counts to confirm.\n",
    "\n",
    "> Re-running is safe: Chroma deduplicates by IDs (we use md5 of file path).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aeed46-feb4-41a9-a28d-ff861b98e08e",
   "metadata": {},
   "source": [
    "üèóÔ∏è Build/Update index"
   ]
  },
  {
   "cell_type": "code",
   "id": "e2a97295-d76c-4340-92ed-dbc414dd92d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:06.558168Z",
     "start_time": "2025-11-07T15:00:04.393524Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "def wipe_collection(name=\"swiss_private_rental_law\"):\n",
    "    chromadb.PersistentClient(path=str(CHROMA_DIR)).delete_collection(name)\n",
    "\n",
    "wipe_collection(\"swiss_private_rental_law\")\n",
    "\"\"\"\n",
    "def build_index(items, batch_size=96, sleep_s=0.0):\n",
    "    \"\"\"\n",
    "    - Batches texts, calls OpenAI embeddings\n",
    "    - Upserts (ids, documents, metadatas, embeddings) into Chroma\n",
    "    \"\"\"\n",
    "    client = get_client()\n",
    "    col = get_collection(client)\n",
    "    print(\"Collection:\", CHROMA_COLLECTION, \"| existing docs:\", col.count())\n",
    "\n",
    "    ids_buf, docs_buf, metas_buf = [], [], []\n",
    "\n",
    "    for it in tqdm(items, desc=\"Indexing\"):\n",
    "        ids_buf.append(it[\"id\"])\n",
    "        docs_buf.append(it[\"text\"])\n",
    "        metas_buf.append(it[\"meta\"])\n",
    "\n",
    "        if len(ids_buf) >= batch_size:\n",
    "            embs = embed_batch(docs_buf)\n",
    "            col.upsert(ids=ids_buf, documents=docs_buf, metadatas=metas_buf, embeddings=embs)\n",
    "            ids_buf, docs_buf, metas_buf = [], [], []\n",
    "            if sleep_s:\n",
    "                time.sleep(sleep_s)\n",
    "\n",
    "    if ids_buf:\n",
    "        embs = embed_batch(docs_buf)\n",
    "        col.upsert(ids=ids_buf, documents=docs_buf, metadatas=metas_buf, embeddings=embs)\n",
    "\n",
    "    print(\"Done. Chunks in collection:\", col.count())\n",
    "    return col\n",
    "\n",
    "collection = build_index(articles)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: swiss_private_rental_law_oai | existing docs: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:01<00:00, 72.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Chunks in collection: 118\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:06.622003Z",
     "start_time": "2025-11-07T15:00:06.612773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assert_collection_dim(col, expected_dim=EXPECTED_DIM):\n",
    "    try:\n",
    "        peek = col.get(limit=1, include=['embeddings'])\n",
    "        if peek.get('embeddings'):\n",
    "            dim = len(peek['embeddings'][0])\n",
    "            if dim != expected_dim:\n",
    "                raise RuntimeError(\n",
    "                    f\"Chroma collection has dim={dim}, expected {expected_dim}. \"\n",
    "                    \"Delete or point to the correct collection.\"\n",
    "                )\n",
    "    except Exception:\n",
    "        pass  # empty collection is fine\n",
    "\n",
    "col = get_collection()\n",
    "assert_collection_dim(col)"
   ],
   "id": "c5dc240ebb43b7bc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "5105b507-32d8-4511-9faf-b2ef2dea6a1f",
   "metadata": {},
   "source": [
    "## Retrieval Helpers\n",
    "\n",
    "- `retrieve(query, k, k_pre)`: embeds the query, does ANN search in Chroma, optionally re-ranks.  \n",
    "- `pack_context(...)`: formats retrieved docs for readability and later prompting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19590d-f0db-4f75-b844-c19ab5ffb363",
   "metadata": {},
   "source": [
    "üß∞ Retrieve & (optional) Re-rank"
   ]
  },
  {
   "cell_type": "code",
   "id": "bab53a3a-02d1-4fe2-a7b0-51c361b9e60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:06.665091Z",
     "start_time": "2025-11-07T15:00:06.659911Z"
    }
   },
   "source": [
    "def retrieve(query: str, k: int = TOP_K, k_pre: int = PRE_K, collection_name: str = CHROMA_COLLECTION):\n",
    "    col = get_collection()\n",
    "    q_emb = embed_query(query)\n",
    "    res = col.query(\n",
    "        query_embeddings=[q_emb],\n",
    "        n_results=k_pre,\n",
    "        include=['documents','metadatas','distances']\n",
    "    )\n",
    "\n",
    "    docs  = res.get('documents', [[]])[0]\n",
    "    metas = res.get('metadatas', [[]])[0]\n",
    "    dists = res.get('distances', [[]])[0]\n",
    "    prelim = list(zip(docs, metas, dists))\n",
    "\n",
    "    # distance ascending (smaller = closer)\n",
    "    prelim = sorted(prelim, key=lambda x: x[2])\n",
    "    return prelim[:k]\n",
    "\n",
    "def pack_context(retrieved, max_chars=8000, per_source_cap=3):\n",
    "    ctx, total, seen = [], 0, {}\n",
    "    for doc, meta, dist in retrieved:\n",
    "        key = (meta.get(\"law\"), meta.get(\"article\"))\n",
    "        seen[key] = seen.get(key, 0) + 1\n",
    "        if seen[key] > per_source_cap:\n",
    "            continue\n",
    "        stamp = f\"[{meta.get('law','?')} {meta.get('title','?')} ‚Äì {meta.get('source')}]\"\n",
    "        block = f\"{stamp}\\n{doc.strip()}\\n\\n\"\n",
    "        if total + len(block) > max_chars:\n",
    "            break\n",
    "        ctx.append(block)\n",
    "        total += len(block)\n",
    "    return \"\".join(ctx)\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "2de213bc-8f8f-4547-95a3-ef9f132513d4",
   "metadata": {},
   "source": [
    "## Quick Tests\n",
    "\n",
    "We try a few canonical questions to verify that:\n",
    "- the right laws show up (OR / VMWG / StGB),\n",
    "- the retrieved articles look relevant,\n",
    "- metadata is present for citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3845f796-8145-40f4-94f6-f56ffe703e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:08.151248Z",
     "start_time": "2025-11-07T15:00:06.710206Z"
    }
   },
   "source": [
    "queries = [\n",
    "    \"Wie fechte ich eine Mietzinserh√∂hung an? Welches Formular ist n√∂tig?\",\n",
    "    \"Welche Rechte habe ich bei M√§ngeln in der Wohnung?\",\n",
    "    \"Ist eine K√ºndigung w√§hrend eines laufenden Schlichtungsverfahrens zul√§ssig?\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"Q:\", q)\n",
    "    hits = retrieve(q, k=5)\n",
    "    for i, (doc, meta, dist) in enumerate(hits, 1):\n",
    "        print(f\"  {i}. [{meta.get('law')} {meta.get('title')}] {meta.get('source')}  dist={dist:.3f}\")\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Wie fechte ich eine Mietzinserh√∂hung an? Welches Formular ist n√∂tig?\n",
      "  1. [OR Art. 269d, Mietzinserh√∂hungen und andere einseitige Vertrags√§nderungen durch den Vermieter] OR.pdf  dist=0.582\n",
      "  2. [VMWG Art. 19 Formular zur Mitteilung von Mietzinserh√∂hungen und anderen einseitigen] VMWG.pdf  dist=0.664\n",
      "  3. [VMWG Art. 20 Begr√ºndungspflicht des Vermieters] VMWG.pdf  dist=0.706\n",
      "  4. [OR Art. 270a, W√§hrend der Mietdauer] OR.pdf  dist=0.726\n",
      "  5. [OR Art. 270, Anfechtung des Mietzinses, Herabsetzungsbegehren, Anfangsmietzins] OR.pdf  dist=0.736\n",
      "\n",
      "Q: Welche Rechte habe ich bei M√§ngeln in der Wohnung?\n",
      "  1. [OR Art. 259a, Rechte des Mieters, Im allgemeinen] OR.pdf  dist=0.579\n",
      "  2. [OR Art. 259, M√§ngel w√§hrend der Mietdauer, Pflicht des Mieters zu kleinen Reinigungen u.] OR.pdf  dist=0.751\n",
      "  3. [OR Art. 267a, Pr√ºfung der Sache und Meldung an den Mieter] OR.pdf  dist=0.753\n",
      "  4. [OR Art. 257g, Meldepflicht] OR.pdf  dist=0.755\n",
      "  5. [OR Art. 259b, Beseitigung des Mangels, Grundsatz] OR.pdf  dist=0.778\n",
      "\n",
      "Q: Ist eine K√ºndigung w√§hrend eines laufenden Schlichtungsverfahrens zul√§ssig?\n",
      "  1. [OR Art. 274e, Schlichtungsverfahren] OR.pdf  dist=0.712\n",
      "  2. [OR Art. 273, Verfahren, Beh√∂rden und Fristen] OR.pdf  dist=0.723\n",
      "  3. [OR Art. 270e, Weitergeltung des Mietvertrages w√§hrend des Anfechtungsverfahrens] OR.pdf  dist=0.773\n",
      "  4. [OR Art. 274f, Gerichtsverfahren] OR.pdf  dist=0.797\n",
      "  5. [OR Art. 271a, K√ºndigung durch den Vermieter] OR.pdf  dist=0.840\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "034b6b11-3c70-4553-9e05-05c37ba29071",
   "metadata": {},
   "source": [
    "üëÄ  Inspect one context block"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b833ca7-67bf-4187-8cbb-fd3b562035c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:08.425836Z",
     "start_time": "2025-11-07T15:00:08.214742Z"
    }
   },
   "source": [
    "sample_q = \"Wie fechte ich eine Mietzinserh√∂hung an? Welches Formular ist n√∂tig?\"\n",
    "hits = retrieve(sample_q, k=6)\n",
    "ctx = pack_context(hits, max_chars=3000)\n",
    "print(ctx[:1500])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OR Art. 269d, Mietzinserh√∂hungen und andere einseitige Vertrags√§nderungen durch den Vermieter ‚Äì OR.pdf]\n",
      "Art. 269d, Mietzinserh√∂hungen und andere einseitige Vertrags√§nderungen durch den Vermieter\n",
      "1 Der Vermieter kann den Mietzins jederzeit auf den n√§chstm√∂glichen K√ºndigungstermin erh√∂hen.\n",
      "Er muss dem Mieter die Mietzinserh√∂hung mindestens zehn Tage vor Beginn der K√ºndigungsfrist\n",
      "auf einem vom Kanton genehmigten Formular mitteilen und begr√ºnden.\n",
      "2 Die Mietzinserh√∂hung ist nichtig, wenn der Vermieter:\n",
      "a. sie nicht mit dem vorgeschriebenen Formular mitteilt;\n",
      "b. sie nicht begr√ºndet;\n",
      "c. mit der Mitteilung die K√ºndigung androht oder ausspricht.\n",
      "3 Die Abs√§tze 1 und 2 gelten auch, wenn der Vermieter beabsichtigt, sonstwie den Mietvertrag\n",
      "einseitig zu Lasten des Mieters zu √§ndern, namentlich seine bisherigen Leistungen zu vermindern\n",
      "oder neue Nebenkosten einzuf√ºhren.\n",
      "\n",
      "[VMWG Art. 19 Formular zur Mitteilung von Mietzinserh√∂hungen und anderen einseitigen ‚Äì VMWG.pdf]\n",
      "Art. 19 Formular zur Mitteilung von Mietzinserh√∂hungen und anderen einseitigen\n",
      "Vertrags√§nderungen\n",
      "(Art. 269d OR)\n",
      "1 Das Formular f√ºr die Mitteilung von Mietzinserh√∂hungen und anderen einseitigen\n",
      "Vertrags√§nderungen\n",
      "im Sinne von Artikel 269d des Obligationenrechts muss enthalten:\n",
      "a. F√ºr Mietzinserh√∂hungen:\n",
      "1. den bisherigen Mietzins und die bisherige Belastung des Mieters f√ºr Nebenkosten;\n",
      "2. den neuen Mietzins und die neue Belastung des Mieters f√ºr Nebenkosten;\n",
      "3. den Zeitpunkt, auf den die Erh√∂hung in Kraft tritt;\n",
      "4. die klare \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "56ddfeee-88a9-4a68-b7e0-78f5cdd2a2dc",
   "metadata": {},
   "source": [
    "# ‚úÖ Summary\n",
    "\n",
    "- We built a **persistent ChromaDB index** from per-article JSONs.  \n",
    "- Retrieval returns focused legal articles with clean metadata for citations.  \n",
    "- Optional cross-encoder rerank is wired (enable if installed).\n",
    "\n",
    "**Next:** `3_Answering_and_Evaluation.ipynb`  \n",
    "We will:\n",
    "- assemble prompts,\n",
    "- answer via **Ollama HTTP** or **OpenAI API**,\n",
    "- enforce a strict output format (1-sentence answer, steps, forms, references),\n",
    "- run a small evaluation set (sanity checks, error cases).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2bb11c63-8ad2-47c2-a264-d8ef9dad907c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:08.438504Z",
     "start_time": "2025-11-07T15:00:08.436661Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76f7990b-6d6c-4cb1-8636-bcde2aa7b793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:00:08.514334Z",
     "start_time": "2025-11-07T15:00:08.512522Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
